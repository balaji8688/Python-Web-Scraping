from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import csv
import json
import time

class RealEstateScraper:
    def __init__(self):
        self.driver = webdriver.Chrome()
        self.data = []
    
    def fetch_page(self, url):
        self.driver.get(url)
        WebDriverWait(self.driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "listing-card"))
        )
        time.sleep(2)  # Ethical delay
    
    def parse_listings(self):
        listings = self.driver.find_elements(By.CLASS_NAME, "listing-card")
        for listing in listings:
            price = listing.find_element(By.CLASS_NAME, "price").text
            beds = listing.find_element(By.CLASS_NAME, "beds").text
            location = listing.find_element(By.CLASS_NAME, "location").text
            self.data.append({
                "price": price,
                "bedrooms": beds,
                "location": location
            })
    
    def paginate(self):
        next_btn = self.driver.find_element(By.CSS_SELECTOR, 'a.next-page')
        if next_btn:
            next_btn.click()
            return True
        return False
    
    def save_data(self):
        # Export to CSV
        with open('real_estate.csv', 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=['price', 'bedrooms', 'location'])
            writer.writeheader()
            writer.writerows(self.data)
        
        # Export to JSON
        with open('real_estate.json', 'w') as f:
            json.dump(self.data, f)
    
    def run(self):
        self.fetch_page("https://www.fakerealestate.com/listings")
        while True:
            self.parse_listings()
            if not self.paginate():
                break
        self.save_data()
        self.driver.quit()

if __name__ == "__main__":
    scraper = RealEstateScraper()
    scraper.run()
